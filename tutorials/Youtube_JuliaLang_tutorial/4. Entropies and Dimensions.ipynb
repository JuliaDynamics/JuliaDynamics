{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.A. Generalized Entropy\n",
    "\n",
    "* In the study of dynamical systems there are many quantities that identify as \"entropy\".\n",
    "* These quantities are not the more commonly known [thermodynamic ones](https://en.wikipedia.org/wiki/Entropy), used in Statistical Physics. \n",
    "* Rather, they are more like the entropies of [information theory](https://en.wikipedia.org/wiki/Entropy_(information_theory), which represent information contained within a dataset. \n",
    "* In general, the more \"uncertain\" or \"random\" the dataset is, the larger its entropy will be. On the other hand, the lower the entropy, the more \"predictable\" the dataset becomes.\n",
    "\n",
    "\n",
    "Let $p$ be an array of probabilities (such that it sums to 1). Then the generalized entropy is defined as \n",
    "\n",
    "$$\n",
    "H_\\alpha(p) = \\frac{1}{1-\\alpha}\\log\\left(\\sum_i p[i]^\\alpha\\right)\n",
    "$$\n",
    "\n",
    "and is also called [Rényi entropy](https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy). Other entropies, like e.g. the [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory) are generalized by it, since at the limit $\\alpha \\to 1$, the Rényi entropy becomes the Shannon entropy,\n",
    "\n",
    "$$\n",
    "H_1(p) = -\\left(\\sum_i p[i] \\log (p[i]) \\right)\n",
    "$$\n",
    "\n",
    "The Rényi entropy can be computed for a specific dataset, given $p$. But how does one get $p$?\n",
    "1. $p$ represents the probability that a point of a dataset falls into a specific \"bin\". \n",
    "2. It is nothing more than the (normalized) histogram of the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicalSystems, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a dataset so that we can start calculating entropies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "randomdata = Dataset(rand(N,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The call signature we need is\n",
    "\n",
    "```julia\n",
    "genentropy(α, ε, dataset::AbstractDataset; base = e)\n",
    "```\n",
    "* This function calculates the generalized entropy of order `α`.\n",
    "* It first calculates the probability array $p$.\n",
    "* The \"histogram\" is created by partitioning the `dataset` into boxes of size `ε`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0.1, 0.01, 0.001, 0.0001]\n",
    "    println(genentropy(2, i, randomdata))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of `genentropy` changed with changing $\\varepsilon$ until we hit $\\varepsilon = 0.001$. \n",
    "\n",
    "At this point the value for the entropy has already saturated. There's no use in partitioning the dataset in smaller boxes. Every bin already contains at most one point.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`genentropy` is conveniently used with outputs of e.g. `trajectory` or `poincaresos`, because they return a `Dataset`.\n",
    "\n",
    "Here we create a trajectory for the towel map, a three dimensional chaotic discrete system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towel = Systems.towel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = trajectory(towel, N-1);\n",
    "summary(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = Matrix(tr)\n",
    "scatter(points[:,1], points[:,2], points[:,3], \n",
    "        markersize=0.3, alpha=0.2, markercolor=:black, \n",
    "        html_output_format=:png, size=(1000, 1000), leg=false, title=\"The towel attractor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and calculate its entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0.1, 0.01, 0.001, 0.0001]\n",
    "    println(genentropy(2, i, tr))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compare the entropy of the above dataset (a trajectory of the towel map) with that of a random dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genentropy(1, 0.01, randomdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As expected, the entropy of the random dataset is higher.\n",
    "\n",
    "---\n",
    "\n",
    "How much time does the computation take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "@btime genentropy(1, 0.01, $tr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.B. Specialized histogram\n",
    "* Partitioning the dataset (i.e. generating a \"histogram\") is in general a costly operation that depends exponentially on the number of dimensions.\n",
    "* In this specific application however, we can tremendously reduce the memory allocation and time spent!\n",
    "\n",
    "To get the array of probabilities `p` for size `ε` from the trajectory of the towel map we use the function `non0hist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ε = 0.01\n",
    "p = non0hist(ε, tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sanity check, showing our probabilities should sum to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does computing the probabilities take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime non0hist($ε, $tr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does this take if we create 9-dimensional data and compare again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = Dataset(rand(N, 9))\n",
    "@btime non0hist($ε, $nine);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`non0hist` uses a very specialized (to-be-published) algorithm and its time does not depend exponentially on the dimensionality of the dataset, instead only linearly. It also has a linearithmic complexity (`n log(n)`) on the number of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.C. Generalized Dimension\n",
    "1. There are numerous methods that one can use to calculate a so-called \"dimension\" of a\n",
    "dataset, like for example the [Fractal dimension](https://en.wikipedia.org/wiki/Fractal_dimension).\n",
    "\n",
    "2. Most of the time these dimensions indicate some kind of scaling behavior. \n",
    "\n",
    "3. For example, the scaling of `genentropy` with decreasing `ε` gives the so-called \"generalized dimension\".\n",
    "\n",
    "\n",
    "$ E \\approx -D\\log(\\varepsilon)$ with $E$ the entropy and $D$ the \"dimension\".\n",
    "\n",
    "---\n",
    "Let's find out the dimension of the attractor of the Towel Map!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towel = Systems.towel()\n",
    "towel_tr = trajectory(towel, 1000000, Ttr = 100);\n",
    "scatter(towel_tr[:, 1], towel_tr[:, 2],\n",
    "        markersize=0.1, alpha=0.2, markercolor=:black, \n",
    "        html_output_format=:png, size=(1000, 1000), leg=false, title=\"The towel attractor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Note that more points = more precision = more computations = more time!)*\n",
    "\n",
    "Now we have to compute `genentropy` for different ε.\n",
    "\n",
    "Which ε should we use...?\n",
    "\n",
    "Let's do a \"random\" guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ες =  10.0 .^ range(-4, stop=1, length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Es = zero(ες)\n",
    "for (i, ε) ∈ enumerate(ες)\n",
    "    Es[i] = genentropy(1, ε, towel_tr)\n",
    "end\n",
    "Es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shorter version (thanks broadcasting!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Es = genentropy.(1, ες, Ref(towel_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*usage of `Ref` ensures broadcasting over `ες` but not over `towel_tr`, which is also iterable. In general, `Ref(x)` causes broadcasting to treat `x` as a scalar.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. Remember that it should be that $E \\approx -D\\log(\\varepsilon)$\n",
    " with $E$ the entropy and $D$ the \"dimension\". \n",
    "\n",
    "Let's plot and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -log.(ες)\n",
    "plot(x, Es, xlabel=\"-log\\\\(\\\\epsilon\\\\)\", ylabel=\"Entropy\", leg=false)\n",
    "plot!([x[4], x[4]], [0, 15], color=:orange)\n",
    "plot!([x[end-3], x[end-3]], [0, 15], color=:orange, size=(500, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the limit of very large ε, all points are in the same bin, and the entropy reaches the minimum of $0$. At the limit of very small ε, every point gets its own bin, and the entropy reaches the maximum of $\\log(N)$ where $N$ is the number of points. In the middle, there is some linear region where this scaling behavior holds. \n",
    "\n",
    "Above, the expected scaling behavior holds between the orange vertical lines.\n",
    "\n",
    "Let's choose the curve points that do fall in the linear regime of the above plot,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = -log.(ες)[4:end-2], Es[4:end-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and find the slope of the curve there, to calculate the dimension, D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ChaosTools\n",
    "offset, slope = ChaosTools.linreg(x, y)\n",
    "D = slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually a correct result, the information dimension of the attractor of the towel map is around 2.\n",
    "\n",
    "---\n",
    "\n",
    "* Are the values of `ες` we used good? \n",
    "* For a general dataset, how can we determine them?\n",
    "\n",
    "the function `estimate_boxsizes(dataset; kwargs...)` can help with that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ες = estimate_boxsizes(towel_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot $E$ vs. $-\\log \\epsilon$ again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Es = genentropy.(1, ες, Ref(towel_tr))\n",
    "plot(-log.(ες), Es, xlabel=\"-log\\\\(\\\\epsilon\\\\)\", ylabel=\"Entropy\", leg=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4.D. Automated Dimension Estimation\n",
    "\n",
    "Given some arbitrary plot like the one above, is there any algorithm to deduce a scaling region?\n",
    "\n",
    "The function `linear_regions(x, y; kwargs...)` decomposes the function `y(x)` into regions where  the function is linear.\n",
    "\n",
    "It returns the indices of `x` that correspond to linear regions and the approximated tangents at each region!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = -log.(ες)\n",
    "lrs, slopes = linear_regions(xs, Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:length(lrs)-1\n",
    "    plot!(xs[lrs[i]:lrs[i+1]], Es[lrs[i]:lrs[i+1]])\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear region which is biggest is the \"probably correct one\". The function `linear_region` estimates its slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_region(xs, Es)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `generalized_dim` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize what we just did to estimate the dimension of an attractor.\n",
    "\n",
    "1. We decided on some partition sizes `ες` to use (the function `estimate_boxsizes` can give an estimate for that).\n",
    "2. For each `ε` in `ες` we calculated the entropy via `genentropy`. We stored these entropies in an array `Es`.\n",
    "3. We tried to find a \"linear scaling region\" of the curve `Es` vs. `-log.(ες)`.\n",
    "4. The slope of this \"linear scaling region\" is the dimension we estimated.\n",
    "\n",
    "Wouldn't it be **cool** if all of this process could happen with one function call?\n",
    "\n",
    "This is *exactly* what the following function does:\n",
    "```julia\n",
    "generalized_dim(α, dataset, ες = estimate_boxsizes(tr))\n",
    "```\n",
    "which computes the `α`-order generalized dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalized_dim(2.0, tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's calculate the dimension of the Henon map that we have seen in previous tutorials,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hen = Systems.henon()\n",
    "tr = trajectory(hen, 200000)\n",
    "generalized_dim(0, tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `generalized_dim` is but a crude estimate!\n",
    "\n",
    "**You must check and double-check and triple-check if you want more accuracy!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirming Takens Theorem\n",
    "\n",
    "Recalling back from notebook 3, we discussed delay embeddings and how Takens theorem states that quantities like e.g. the attractor dimension remain the same between reconstructed and original systems.\n",
    "\n",
    "We can now show this numerically. We start with a trajectory from the system we used in notebook 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Systems.gissinger(ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.05\n",
    "data = trajectory(g, 20000.0, dt = dt, Ttr = 100.0)\n",
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate a good delay time using the first minimum of the mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "τ = estimate_delay(data[:, 1], \"mi_min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And embed the timeseries in three dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = embed(data[:, 1], 3, τ)\n",
    "summary(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `generalized_dim` we can now compare the dimension estimated for the original trajectory `data` and the reconstructed trajectory `R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalized_dim(1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalized_dim(1, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
