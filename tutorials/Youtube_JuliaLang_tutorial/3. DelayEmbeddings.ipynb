{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.A. How we handle numerical data in the ecosystem\n",
    "\n",
    "In many previous examples it was often the case that the returned result of a function was a `Dataset`. For example `trajectory` and `poincaresos` return a `Dataset`.\n",
    "\n",
    "What is a `Dataset`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicalSystems, Plots\n",
    "dataset = Dataset(rand(1000, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` is how we handle numerical data in **DynamicalSystems.jl**. In essense it is a wrapper of `Vector{SVector}` (staticallly sized vectors). Besides that, `Dataset` has matrix-like indexing support:\n",
    "\n",
    "* when accessing a `Dataset` with a single index it acts as a vector of static vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof( dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.0\n",
    "for point in dataset # point is a static vector\n",
    "    x += point[1] - point[2]\n",
    "end\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* when accessed with two indices a `Dataset` acts _like_ a matrix where each _row_ is one data point. Equivalently, it is accessed as the matrix it is printed like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1, 2] == dataset[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.B. Delay Coordinates Embedding\n",
    "Let's say you have a \"real-world system\" which you measure in an experiment or so. You are assuming that the system is composed of several dynamic variables, but you can only measure one of them (or some function of the variable).\n",
    "\n",
    "You have a severe lack of recorded information for the system. What do you do?\n",
    "1. Give up on science, it is a complete waste of time.\n",
    "2. Use [Takens theorem](https://en.wikipedia.org/wiki/Takens%27s_theorem), which is indistinguishable from magic.\n",
    "\n",
    "**DynamicalSystems.jl** suggests the latter.\n",
    "\n",
    "From a timeseries $s$ one can *reconstruct* a state-space $\\mathbf{z}$ simply by shifting $s$ in time, like\n",
    "  \n",
    "  $$\\mathbf{z}(n) = (s(n), s(n+\\tau), s(n+2\\tau), \\dots, s(n+\\gamma\\tau))$$\n",
    "  \n",
    "This is done with the `reconstruct(s, γ, τ)` function or the `embed(s, D, τ)` function (with the embedding dimension `D = γ + 1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rand(100000)\n",
    "γ = 3 # how many temporal neighbors?\n",
    "τ = 1 # delay time\n",
    "R = reconstruct(s, γ, τ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reconstruct` and `embed` return a `Dataset` as well. Because of this they are very fast to compute!\n",
    "\n",
    "## But how is this even helpful?\n",
    "\n",
    "What we have done is more than just a fancy way to produce a higher dimensional dataset out of a univariate timeseries. For a proper choice of `τ, γ` [Takens theorem](https://en.wikipedia.org/wiki/Takens%27s_theorem) says that the reconstructed trajectory is homeomorphic with a true, real trajectory of that dynamical system that we got `s` from.\n",
    "\n",
    "In sort, many quantities like e.g. the Lyapunov exponents, the dimension of the attracting set, etc., are the same for the real dynamical system and the one we reconstructed here numerically. **Even though we are clueless of how many variables the system may have in reality**.\n",
    "\n",
    "We will be confirming this concept numerically in the next notebook.\n",
    "\n",
    "\n",
    "## How does a reconstruction look?\n",
    "The `gissinger` system is a 3D chaotic continuous system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Systems.gissinger(ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicalSystemsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.05\n",
    "data = trajectory(ds, 2000.0, dt = dt, Ttr=10)\n",
    "\n",
    "xyz = columns(data)\n",
    "\n",
    "plot(xyz..., leg=false, title=\"Gissinger attractor\", color=:black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(columns(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some some examples of reconstructions of the `gissinger` system, using each of the variables of the system, different delay times and embedding dimension of `2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Systems.gissinger(ones(3)) # 3D continuous chaotic system, also shown in orbit diagrams tutorial\n",
    "dt = 0.05\n",
    "data = trajectory(ds, 2000.0, dt = dt)\n",
    "\n",
    "\n",
    "k = 1\n",
    "subplots = []\n",
    "for i in 1:3, j in 1:3\n",
    "    τ =  [5, 30, 100][j]\n",
    "    R = reconstruct(xyz[i], 1, τ)\n",
    "    push!(subplots, plot(R[:, 1], R[:, 2], color = :black, lw = 0.8, title=\"var = $i, \\\\tau = $τ\"))\n",
    "    k+=1\n",
    "end\n",
    "\n",
    "subplots = reshape(subplots, 3,3)\n",
    "plot(subplots..., layout=(3,3), size=(1000, 1000), legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone familiar with delay coordinates embadding, will see that `τ = 5` is too small while `τ = 100` is too big. `τ = 30` seems okay, but it is not possible to say if it is optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.C. Estimating an optimal delay time\n",
    "\n",
    "It is important to understand that for Takens theorem to work one still has to choose \"appropriately good\" values for both the delay time as well as the embedding dimension!\n",
    "\n",
    "Thankfully, **DynamicalSystems.jl** has full support for that as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `estimate_delay` estimates delay time `τ` using the autocorrelation of the signal\n",
    "* `estimate_dimension` returns an estimator for the amount of temporal neighbors `γ` using Cao's method\n",
    "\n",
    "Let's focus on `estimate_delay` for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?estimate_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For the `gissinger` system above, by looking at the reconstruction plots it seems that a delay time close `30` is a good value.\n",
    "\n",
    "Let's use some methods for `estimate_delay` and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data[:, 1]\n",
    "\n",
    "methods = [\"ac_zero\", \"mi_min\", \"exp_decay\"]\n",
    "for method in methods\n",
    "    τ = estimate_delay(s, method, 0:1:400)\n",
    "    println(\"For method = $(method), τ = $τ\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we observe is that \"zero of autocorrelation\" method failed completely. Also, the \"correlation exponential decay\" method returned a very bad result. These methods are useful only in specific cases: the first one when the autocorrelation function is oscillatory, and the latter when the correlation decays as an exponential.\n",
    "\n",
    "On the other side, the first minimum of the mutual information is generally helpful (but also most costly to compute).\n",
    "\n",
    "---\n",
    "\n",
    "Let's plot the autocorrelation function and the mutual information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "\n",
    "τ = 0:400\n",
    "ac = autocor(s, τ)\n",
    "mi = mutualinformation(s, τ)\n",
    "plot(τ, mi ./ maximum(mi), label = \"mutual information\")\n",
    "plot!(τ, ac, label = \"autocorrelation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation not only never crosses zero, but also doesn't decay as an exponential. On the other side, the first minimum of the mutual information of `s` with itself has a value very close to what made sense from plotting the reconstructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.D. Fast (self-)Mutual Information\n",
    "\n",
    "A good method for estimating a proper delay time is the mutual information between a timeseries `s` and itself shifted in time. The function `mutualinformation` computes this quantity. Internally it uses an advanced (to-be-published) algorithm that improves existing standards and can reach high speeds. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time mutualinformation(s, 1:100)\n",
    "println(\"For length: \", length(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
